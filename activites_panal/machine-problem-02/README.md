# Machine Problem 2: Evaluating Machine Learning Model Performance

## ğŸ“‹ Overview

This project implements and evaluates a **Logistic Regression** classification model using the Breast Cancer Wisconsin dataset. It demonstrates a complete data science workflow from data preprocessing to model evaluation and interpretation.

## ğŸ“Š Dataset

**Breast Cancer Wisconsin (Diagnostic) Dataset**

- **Source:** scikit-learn built-in dataset
- **Samples:** 569
- **Features:** 30 numeric features computed from digitized images
- **Target:** Binary classification (Malignant = 0, Benign = 1)

## ğŸ¯ Learning Objectives

1. Apply data preprocessing, train-test split, and model training techniques
2. Implement logistic regression for classification tasks
3. Evaluate model performance using confusion matrix and learning curves
4. Apply 5-fold cross-validation to validate model reliability
5. Interpret and communicate model results accurately

## ğŸ“ Project Structure

```
machine-problem-02/
â”œâ”€â”€ logistic_regression.ipynb   # Main Jupyter notebook with all code
â”œâ”€â”€ learning_curve.png          # Learning curve visualization
â”œâ”€â”€ confusion_matrix.png        # Confusion matrix visualization
â”œâ”€â”€ cross_validation.txt        # 5-Fold CV results summary
â”œâ”€â”€ report.md                   # Interpretation and findings report
â””â”€â”€ README.md                   # This file
```

## ğŸ› ï¸ Requirements

```python
numpy
pandas
matplotlib
seaborn
scikit-learn
```

## ğŸš€ How to Run

1. **Install dependencies:**

   ```bash
   pip install numpy pandas matplotlib seaborn scikit-learn
   ```

2. **Open the Jupyter Notebook:**

   ```bash
   jupyter notebook logistic_regression.ipynb
   ```

3. **Run all cells:**
   - Click "Kernel" â†’ "Restart & Run All"
   - Or run cells individually with Shift + Enter

## ğŸ“ˆ Key Results

| Metric                | Score       |
| --------------------- | ----------- |
| Training Accuracy     | ~98.7%      |
| Testing Accuracy      | ~97.4%      |
| Cross-Validation Mean | ~96.5% Â± 2% |
| Precision             | ~98%        |
| Recall                | ~97%        |
| F1-Score              | ~97%        |

## ğŸ† Bonus Challenge (+10 pts)

The notebook includes a comparison with other classifiers:

- Decision Tree Classifier
- K-Nearest Neighbors (KNN)
- Support Vector Machine (SVM)

## ğŸ“ Author

CSST102 - Basic Machine Learning  
Academic Year: 2025-2026
